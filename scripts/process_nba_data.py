#!/usr/bin/env python3
"""
Process NBA Player Data and Stats

This script reads player and stats data from JSON files (generated by 
sync_nba_players_with_stats.py), processes it, calculates impact and astro scores,
and upserts the data into Supabase tables: `players` and `basketball_stats`.
"""

import os
import sys
import json
import logging
import glob
from datetime import datetime
from typing import Dict, List, Any, Optional

import psycopg2
from psycopg2.extras import execute_values
from dotenv import load_dotenv

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# --- Database Configuration ---
DB_HOST = os.getenv("DB_HOST_INTERNAL") # Use internal if script runs in same network as Supabase
DB_PORT = os.getenv("DB_PORT_INTERNAL", "5432")
DB_NAME = os.getenv("DB_NAME", "postgres")
DB_USER = os.getenv("DB_USER", "postgres")
DB_PASSWORD = os.getenv("DB_PASSWORD_INTERNAL")

# --- Helper Functions ---

def get_db_connection():
    """Establishes a connection to the PostgreSQL database."""
    try:
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        return conn
    except Exception as e:
        logger.error(f"Error connecting to the database: {e}")
        raise

def find_latest_json_file(pattern: str) -> Optional[str]:
    """Finds the most recently created JSON file matching a pattern."""
    try:
        files = glob.glob(pattern)
        if not files:
            return None
        latest_file = max(files, key=os.path.getctime)
        return latest_file
    except Exception as e:
        logger.error(f"Error finding latest JSON file for pattern {pattern}: {e}")
        return None

# --- Score Calculation Functions ---

def calculate_nba_impact_score(per_game_stats: Dict[str, Any]) -> Optional[float]:
    """Calculates the NBA Impact Score based on per-game player stats.
    Formula: (Points * 0.4) + (Rebounds * 0.25) + (Assists * 0.25) + 
             (Steals * 0.35) + (Blocks * 0.3) - (Turnovers * 0.3) + 
             (Field Goal Percentage * 15) + (Three Point Percentage * 10) - 
             (Personal Fouls * 0.2)
    """
    try:
        # Ensure all required stats are present and are numbers
        pts_pg = float(per_game_stats.get('points_per_game', 0))
        reb_pg = float(per_game_stats.get('rebounds_per_game', 0))
        ast_pg = float(per_game_stats.get('assists_per_game', 0))
        stl_pg = float(per_game_stats.get('steals_per_game', 0))
        blk_pg = float(per_game_stats.get('blocks_per_game', 0))
        tov_pg = float(per_game_stats.get('turnovers_per_game', 0)) # Needs to be added to basketball_stats
        fg_pct = float(per_game_stats.get('field_goal_pct', 0))
        fg3_pct = float(per_game_stats.get('three_point_pct', 0))
        pf_pg = float(per_game_stats.get('personal_fouls_per_game', 0)) # Needs to be added to basketball_stats

        impact_score = (
            (pts_pg * 0.4) +
            (reb_pg * 0.25) +
            (ast_pg * 0.25) +
            (stl_pg * 0.35) +
            (blk_pg * 0.3) -
            (tov_pg * 0.3) +
            (fg_pct * 15) +
            (fg3_pct * 10) -
            (pf_pg * 0.2)
        )
        return round(impact_score, 2)
    except (TypeError, ValueError) as e:
        logger.error(f"Error calculating impact score due to invalid data type: {e} for stats {per_game_stats}")
        return None
    except Exception as e:
        logger.error(f"An unexpected error occurred during impact score calculation: {e}")
        return None

def calculate_nba_astro_score(player_uuid: str, birth_date: Optional[datetime.date], conn) -> Optional[float]:
    """Placeholder for NBA Astro Score calculation.
    The actual Astro Score is calculated by a Supabase Edge Function named 'calculate-astro-score'.
    This Python script does not replicate or invoke that Edge Function.
    """
    # Details of the 'calculate-astro-score' Edge Function (based on user info):
    # - Inputs: player_id (UUID), birth_date (DATE).
    # - Data Fetched from 'astrological_data' table:
    #   - For the game date (current date for general score, or specific game_date):
    #     - moon_phase
    #     - moon_sign
    #     - planetary_signs (as 'transits')
    #   - For the player's birth_date:
    #     - planetary_signs (as 'natal_chart_signs')
    # - Logic:
    #   - Compares signs in natal_chart_signs with signs in transits.
    #   - Identifies astrological aspects (e.g., conjunction, opposition, trine, square)
    #     between natal planets and transiting planets.
    #   - A scoring system is applied based on the strength and nature of these aspects.
    #     (e.g., Trine Sun-Jupiter might be +X points, Square Mars-Saturn might be -Y points).
    # - The Edge Function would then update `players.astro_score` or return the score.

    if not birth_date:
        logger.warning(f"Birth date not available for player UUID {player_uuid}. Astro Score (via Edge Function) would require it.")
        # Return None or a default placeholder if the script were to update it.
        # Since the Edge Function handles it, this Python script's return here is purely a placeholder.
        return None 

    logger.info(f"Astro Score for player UUID {player_uuid} (birth_date: {birth_date}) is calculated by the 'calculate-astro-score' Supabase Edge Function.")
    # This script will use a placeholder value if it were to update the score directly.
    # The actual update mechanism for astro_score (triggered by Edge Function or other process) is external to this script.
    return None # This function is now purely informational; score comes from Edge Function

# --- Data Processing and Upsert Functions ---

def upsert_players_data(conn, players_data: List[Dict[str, Any]]) -> Dict[int, str]:
    """Upserts player information into the 'players' table.
    Returns a mapping of MySportsFeeds ID to internal Player UUID.
    """
    if not players_data:
        logger.info("No player data to upsert.")
        return {}

    msf_id_to_uuid_map = {}
    rows_to_insert = []

    with conn.cursor() as cur:
        # Get existing players by mysportsfeeds_id to avoid duplicates and get UUIDs
        existing_msf_ids = {row[0]: row[1] for row in cur.execute("SELECT mysportsfeeds_id, id FROM players WHERE mysportsfeeds_id IS NOT NULL") or []}
        msf_id_to_uuid_map.update(existing_msf_ids)

        for player_api_data in players_data:
            player_details = player_api_data.get('player', {})
            msf_id = player_details.get('id')
            if not msf_id:
                logger.warning(f"Skipping player with no MySportsFeeds ID: {player_details.get('firstName')} {player_details.get('lastName')}")
                continue

            # TODO: Map MySportsFeeds team ID to your internal team_id UUID
            team_msf_id = player_details.get('currentTeam', {}).get('id')
            internal_team_uuid = get_internal_team_uuid(cur, team_msf_id) if team_msf_id else None

            birth_date_str = player_details.get('birthDate')
            birth_date = datetime.strptime(birth_date_str, '%Y-%m-%d').date() if birth_date_str else None

            if msf_id not in msf_id_to_uuid_map:
                 # New player, prepare for insert and get new UUID
                player_uuid = None # Will be generated by DB or fetched after insert
                # For now, we'll insert and then query back, or assume we can get it.
                # This part needs refinement based on how you want to handle new UUIDs.
                # A common pattern is to insert and then retrieve the ID, or batch insert and query.

                # For simplicity in this draft, we'll prepare data for batch upsert
                # and handle ID mapping later if needed for stats.
                # This assumes 'mysportsfeeds_id' is the primary key for matching from API data.
                row = (
                    player_details.get('firstName', '') + ' ' + player_details.get('lastName', ''),
                    birth_date,
                    'basketball', # sport_type
                    internal_team_uuid, # team_id
                    None, # win_shares (MySportsFeeds player_stats_totals doesn't provide this directly)
                    msf_id # mysportsfeeds_id
                    # impact_score and astro_score will be updated later
                )
                rows_to_insert.append(row)
            else:
                # Player exists, maybe update some fields if necessary (not shown here for brevity)
                pass
        
        if rows_to_insert:
            # Upsert into players table
            # Assumes mysportsfeeds_id is unique. If not, this needs ON CONFLICT DO UPDATE.
            # For players table, we might want to insert if not exists by mysportsfeeds_id
            # and then update other fields.
            insert_query = """
            INSERT INTO players (name, birth_date, sport_type, team_id, win_shares, mysportsfeeds_id)
            VALUES %s
            ON CONFLICT (mysportsfeeds_id) DO UPDATE SET
                name = EXCLUDED.name,
                birth_date = EXCLUDED.birth_date,
                sport_type = EXCLUDED.sport_type,
                team_id = EXCLUDED.team_id,
                win_shares = EXCLUDED.win_shares,
                updated_at = NOW()
            RETURNING mysportsfeeds_id, id;
            """
            logger.info(f"Upserting {len(rows_to_insert)} players...")
            inserted_ids = execute_values(cur, insert_query, rows_to_insert, template=None, page_size=100, fetch=True)
            for msf_id_val, uuid_val in inserted_ids:
                msf_id_to_uuid_map[msf_id_val] = str(uuid_val)
            conn.commit()
            logger.info(f"Successfully upserted/updated {len(inserted_ids)} players.")
        else:
            logger.info("No new players to insert. Existing players might have been updated if logic was added.")

    return msf_id_to_uuid_map

def upsert_basketball_stats(conn, stats_data: List[Dict[str, Any]], player_id_map: Dict[int, str]):
    """Upserts player statistics into the 'basketball_stats' table."""
    if not stats_data:
        logger.info("No stats data to upsert.")
        return

    rows_to_upsert = []
    # Season determination: MySportsFeeds API response for player_stats_totals includes
    # references.seasonReferences[0].season (e.g., 2023 for 2023-24 season).
    # This should be extracted from the JSON file if available per entry or globally for the file.

    for stat_entry in stats_data:
        player_api_info = stat_entry.get('player', {})
        msf_player_id = player_api_info.get('id')
        
        if not msf_player_id or msf_player_id not in player_id_map:
            logger.warning(f"Skipping stats for player MSF ID {msf_player_id} - not found in player_id_map.")
            continue
        
        internal_player_uuid = player_id_map[msf_player_id]
        player_stats_obj = stat_entry.get('stats', {})
        games_played = player_stats_obj.get('gamesPlayed', 0)

        # Determine season for the stats entry
        # Prefer season from stat_entry's references if available, else fall back or log warning
        # Example structure: stat_entry.get('references', {}).get('seasonReferences', [{}])[0].get('season')
        # For now, using a placeholder. This needs to be robustly determined from input JSON.
        entry_season_year = stat_entry.get('references', {}).get('seasonReferences', [{}])[0].get('season')
        if entry_season_year is None:
            # Fallback: try to get it from a global context if the file implies a single season
            # Or use the season passed to the API if that's how files are named/structured.
            # As a last resort for this draft, using current year, but this is likely incorrect for past data.
            logger.warning(f"Season year not found in stat entry for MSF ID {msf_player_id}. Defaulting to current year. THIS NEEDS ATTENTION.")
            entry_season_year = datetime.now().year 
        else:
            entry_season_year = int(entry_season_year) # Ensure it's an integer

        # Helper to safely get and convert stat, returning None if not possible
        def get_stat(obj, key, default=0):
            val = obj.get(key)
            if val is None: return default
            try: return float(val) # Ensure numeric for calculations
            except (ValueError, TypeError): return default

        # Per-game calculations (if games_played > 0)
        pts_pg = get_stat(player_stats_obj.get('offense', {}), 'pts') / games_played if games_played > 0 else 0
        ast_pg = get_stat(player_stats_obj.get('offense', {}), 'ast') / games_played if games_played > 0 else 0
        reb_pg = get_stat(player_stats_obj.get('rebounds', {}), 'reb') / games_played if games_played > 0 else 0
        stl_pg = get_stat(player_stats_obj.get('defense', {}), 'stl') / games_played if games_played > 0 else 0
        blk_pg = get_stat(player_stats_obj.get('defense', {}), 'blk') / games_played if games_played > 0 else 0
        min_seconds = get_stat(player_stats_obj.get('miscellaneous', {}), 'minSeconds')
        min_pg = (min_seconds / 60) / games_played if games_played > 0 and min_seconds is not None else 0
        tov_pg = get_stat(player_stats_obj.get('offense', {}), 'tov') / games_played if games_played > 0 else 0
        pf_pg = get_stat(player_stats_obj.get('defense', {}), 'foulPers') / games_played if games_played > 0 else 0

        row = (
            internal_player_uuid,
            entry_season_year, # Use determined season year for this stats entry
            games_played,
            round(pts_pg, 2),
            round(ast_pg, 2),
            round(reb_pg, 2),
            round(stl_pg, 2),
            round(blk_pg, 2),
            get_stat(player_stats_obj.get('fieldGoals', {}), 'fgPct'),
            get_stat(player_stats_obj.get('fieldGoals', {}), 'fg3PtPct'),
            get_stat(player_stats_obj.get('freeThrows', {}), 'ftPct'),
            round(min_pg, 2),
            None, # player_efficiency_rating (PER) - not directly available
            round(tov_pg, 2), # turnovers_per_game
            round(pf_pg, 2)   # personal_fouls_per_game
        )
        rows_to_upsert.append(row)

    if rows_to_upsert:
        upsert_query = """
        INSERT INTO basketball_stats (
            player_id, season, games_played, points_per_game, assists_per_game, 
            rebounds_per_game, steals_per_game, blocks_per_game, field_goal_pct, 
            three_point_pct, free_throw_pct, minutes_per_game, player_efficiency_rating,
            turnovers_per_game, personal_fouls_per_game
        )
        VALUES %s
        ON CONFLICT (player_id, season) DO UPDATE SET
            games_played = EXCLUDED.games_played,
            points_per_game = EXCLUDED.points_per_game,
            assists_per_game = EXCLUDED.assists_per_game,
            rebounds_per_game = EXCLUDED.rebounds_per_game,
            steals_per_game = EXCLUDED.steals_per_game,
            blocks_per_game = EXCLUDED.blocks_per_game,
            field_goal_pct = EXCLUDED.field_goal_pct,
            three_point_pct = EXCLUDED.three_point_pct,
            free_throw_pct = EXCLUDED.free_throw_pct,
            minutes_per_game = EXCLUDED.minutes_per_game,
            player_efficiency_rating = EXCLUDED.player_efficiency_rating,
            turnovers_per_game = EXCLUDED.turnovers_per_game,
            personal_fouls_per_game = EXCLUDED.personal_fouls_per_game,
            updated_at = NOW();
        """
        logger.info(f"Upserting {len(rows_to_upsert)} basketball stats records...")
        with conn.cursor() as cur:
            execute_values(cur, upsert_query, rows_to_upsert, template=None, page_size=100)
            conn.commit()
        logger.info(f"Successfully upserted {len(rows_to_upsert)} basketball stats records.")

def get_internal_team_uuid(cursor, msf_team_id: int) -> Optional[str]:
    """Fetches the internal UUID for a team given its MySportsFeeds ID.
    Assumes a 'teams' table with 'msf_team_id' (MySportsFeeds Team ID) and 'id' (UUID) columns.
    """
    # TODO: Confirm 'teams' table structure and column names with the user.
    if msf_team_id is None:
        return None
    try:
        cursor.execute("SELECT id FROM teams WHERE msf_team_id = %s;", (msf_team_id,))
        result = cursor.fetchone()
        if result:
            return str(result[0])
        else:
            logger.warning(f"Internal team UUID not found for MySportsFeeds team ID (msf_team_id): {msf_team_id}")
            return None
    except Exception as e:
        logger.error(f"Error fetching internal team UUID for MSF ID {msf_team_id}: {e}")
        return None

def update_player_scores(conn, player_id_map: Dict[int, str]):
    """Calculates and updates impact and astro scores for players."""
    logger.info("Updating player scores...")
    updates = []
    current_processing_season = None # Will be determined by the stats data being processed

    with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
        # Determine the season to process scores for. 
        # This assumes that the stats processed into basketball_stats are for a single, consistent season.
        # A more robust solution might involve iterating through all seasons for each player if necessary.
        # For now, we'll try to infer it from one of the player's recently updated stats.
        if player_id_map:
            # Get a sample player UUID to find their latest season in basketball_stats
            sample_msf_id = list(player_id_map.keys())[0]
            sample_player_uuid = player_id_map[sample_msf_id]
            cur.execute("SELECT season FROM basketball_stats WHERE player_id = %s ORDER BY season DESC LIMIT 1;", (sample_player_uuid,))
            season_row = cur.fetchone()
            if season_row:
                current_processing_season = season_row['season']
                logger.info(f"Determined current processing season for scores as: {current_processing_season}")
            else:
                logger.warning(f"Could not determine current processing season for player {sample_player_uuid}. Scores might not be updated.")
                return
        else:
            logger.info("No players in map, skipping score updates.")
            return

        for msf_id, player_uuid in player_id_map.items():
            cur.execute("SELECT birth_date FROM players WHERE id = %s;", (player_uuid,))
            player_info_row = cur.fetchone()
            birth_date = player_info_row['birth_date'] if player_info_row else None

            # Fetch per-game stats from basketball_stats for the current_processing_season
            cur.execute(
                "SELECT * FROM basketball_stats WHERE player_id = %s AND season = %s;", 
                (player_uuid, current_processing_season)
            )
            stats_row = cur.fetchone()

            impact_score = None
            if stats_row:
                # Convert stats_row (DictRow) to a simple dict for the calculation function
                per_game_stats_for_calc = dict(stats_row)
                impact_score = calculate_nba_impact_score(per_game_stats_for_calc)
            else:
                logger.warning(f"No stats found for player UUID {player_uuid}, season {current_processing_season}. Cannot calculate Impact Score.")

            # Astro Score is calculated and updated by a separate nightly cron job ('calculate-astro-score' Edge Function).
            # This script will not update astro_score.
            
            if impact_score is not None:
                updates.append((impact_score, player_uuid)) # Only impact_score and player_uuid

        if updates:
            logger.info(f"Updating Impact Scores for {len(updates)} players...")
            # Using a loop for updates for clarity, batching could be more performant
            for impact, uuid_val in updates:
                cur.execute(
                    "UPDATE players SET impact_score = %s, updated_at = NOW() WHERE id = %s;",
                    (impact, uuid_val)
                )
            conn.commit()
            logger.info(f"Successfully updated scores for {len(updates)} players.")
        else:
            logger.info("No player scores to update (either no new scores calculated or no players processed).")

# --- Main Execution --- 

def main():
    logger.info("Starting NBA data processing and database sync...")
    
    # Find the latest player and stats JSON files
    players_file_pattern = "nba_players_*.json"
    stats_file_pattern = "nba_player_stats_*.json"
    
    latest_players_file = find_latest_json_file(players_file_pattern)
    latest_stats_file = find_latest_json_file(stats_file_pattern)
    
    if not latest_players_file:
        logger.error(f"No player data file found matching {players_file_pattern}. Exiting.")
        sys.exit(1)
    if not latest_stats_file:
        logger.error(f"No player stats file found matching {stats_file_pattern}. Exiting.")
        sys.exit(1)
        
    logger.info(f"Using player data file: {latest_players_file}")
    logger.info(f"Using player stats file: {latest_stats_file}")
    
    try:
        with open(latest_players_file, 'r') as f:
            players_data_from_file = json.load(f)
        with open(latest_stats_file, 'r') as f:
            stats_data_from_file = json.load(f)
    except Exception as e:
        logger.error(f"Error reading JSON data files: {e}")
        sys.exit(1)

    conn = None
    try:
        conn = get_db_connection()
        
        # Step 1: Upsert player data and get mapping of MSF ID to Player UUID
        # This part needs careful implementation of how you map MySportsFeeds team IDs to your internal team_id UUIDs.
        # The current placeholder for team_id in upsert_players_data will result in NULLs.
        player_id_map = upsert_players_data(conn, players_data_from_file)
        logger.info(f"Player ID map created/updated with {len(player_id_map)} entries.")

        # Step 2: Upsert basketball stats using the player_id_map
        upsert_basketball_stats(conn, stats_data_from_file, player_id_map)
        
        # Step 3: Calculate and update impact and astro scores
        # This step requires the actual formulas and potentially more data fetching logic within calculate_... functions.
        update_player_scores(conn, player_id_map)
        
        logger.info("NBA data processing and sync complete!")
        
    except Exception as e:
        logger.error(f"An error occurred during the data processing: {e}", exc_info=True)
        if conn:
            conn.rollback()
    finally:
        if conn:
            conn.close()
            logger.info("Database connection closed.")

if __name__ == "__main__":
    main()
